{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d8c2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683aef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_data = pd.read_csv('PD_data_choice.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d507e295",
   "metadata": {},
   "source": [
    "### BRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22211042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_brl_loglikelihood(sub_data, beta_param, bias, gamma_pos, gamma_neg):\n",
    "    \"\"\"\n",
    "    Bayesian Reinforcement Learning log-likelihood function for Iterative Prisoner's Dilemma\n",
    "    \n",
    "    Parameters:\n",
    "    sub_data: DataFrame with subject data (80 rounds per subject)\n",
    "    beta_param: softmax temperature parameter for the player\n",
    "    bias: bias parameter\n",
    "    gamma_pos: learning rate for cooperative outcomes\n",
    "    gamma_neg: learning rate for defective outcomes\n",
    "    \n",
    "    Returns:\n",
    "    BayesLL: negative log-likelihood\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read trial parameters\n",
    "    trial = sub_data['round_number'].values\n",
    "    p1_choice = sub_data['p1_choice'].values\n",
    "    p2_choice = sub_data['p2_choice'].values\n",
    "    \n",
    "    # Number of trials\n",
    "    num_trials = len(trial)\n",
    "    \n",
    "    # Initialize priors for each 'player type': uniform probability\n",
    "    a_init = 1.01\n",
    "    b_init = 1.01\n",
    "    \n",
    "    # Set alpha and beta for each 'player type'\n",
    "    a = a_init\n",
    "    b = b_init\n",
    "    \n",
    "    # Store mean beta distribution and log likelihood\n",
    "    mew = np.zeros(num_trials)\n",
    "    loglike = np.zeros(num_trials)\n",
    "    \n",
    "    # Loop over trials\n",
    "    for t in range(num_trials):\n",
    "        # Beta distribution to compute chris's probability of cooperating\n",
    "        mew[t] = a / (a + b)\n",
    "        \n",
    "        # Human choice probability\n",
    "        if p1_choice[t] == 1:  # probability of cooperating\n",
    "            choice_prob = np.exp(beta_param * mew[t]) / (np.exp(beta_param * mew[t]) + np.exp(beta_param * bias))\n",
    "        else:  # probability of defecting\n",
    "            choice_prob = 1 - np.exp(beta_param * mew[t]) / (np.exp(beta_param * mew[t]) + np.exp(beta_param * bias))\n",
    "        \n",
    "        # Update strategies based on partner's action\n",
    "        if p2_choice[t] == 1:\n",
    "            a += 1  # cooperate\n",
    "        else:\n",
    "            b += 1  # defect\n",
    "        \n",
    "        a_prev = a\n",
    "        b_prev = b\n",
    "        \n",
    "        # Implement learning rate\n",
    "        a = a_prev * gamma_pos  # cooperate LR\n",
    "        b = b_prev * gamma_neg  # defect LR\n",
    "        \n",
    "        # Get trial log-likelihood\n",
    "        loglike[t] = np.log(choice_prob)\n",
    "    \n",
    "    # Return negative sum of log-likelihood\n",
    "    bayes_ll = -np.sum(loglike)\n",
    "    return bayes_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9738c094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting subjects: 100%|██████████| 142/142 [01:50<00:00,  1.28subject/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bounds = [(1, 20), (0.1, 1), (0.1, 1), (0.1, 1)]\n",
    "    \n",
    "# Initialize results dictionary\n",
    "params = {\n",
    "    'subjNum': [],\n",
    "    'subjBetaParam': [],\n",
    "    'subjBias': [],\n",
    "    'subjGammaPos': [],\n",
    "    'subjGammaNeg': [],\n",
    "    'subjBayesLL': []\n",
    "}\n",
    "\n",
    "# Subject list\n",
    "sub_list = task_data['ppt_number'].unique()\n",
    "\n",
    "for sub_num in tqdm(sub_list, desc=\"Fitting subjects\", unit=\"subject\"):\n",
    "    \n",
    "    # Get subject data\n",
    "    sub_data = task_data[task_data['ppt_number'] == sub_num].copy()\n",
    "    \n",
    "    # Remove NaNs\n",
    "    sub_data = sub_data.dropna()\n",
    "    \n",
    "    # Set number of iterations/starting points\n",
    "    n_iter = 20\n",
    "    \n",
    "    if not sub_data.empty:  # if we have data for subject to model\n",
    "        \n",
    "        results = []\n",
    "        likelihoods = []\n",
    "        \n",
    "        for iteration in range(n_iter):\n",
    "            # Random initial values\n",
    "            np.random.seed()\n",
    "            init_vals = [\n",
    "                np.random.rand() * 20,                    # beta_param: 0-20\n",
    "                (np.random.rand() + 0.1) * 0.9,         # bias: 0.1-1\n",
    "                (np.random.rand() + 0.1) * 0.9,         # gamma_pos: 0.1-1\n",
    "                (np.random.rand() + 0.1) * 0.9          # gamma_neg: 0.1-1\n",
    "            ]\n",
    "            \n",
    "            # Optimize parameters\n",
    "            def objective(x):\n",
    "                return pd_brl_loglikelihood(sub_data, x[0], x[1], x[2], x[3])\n",
    "            \n",
    "            try:\n",
    "                result = minimize(objective, init_vals, bounds=bounds, method='L-BFGS-B')\n",
    "                results.append(result.x)\n",
    "                likelihoods.append(result.fun)\n",
    "            except:\n",
    "                # If optimization fails, skip this iteration\n",
    "                continue\n",
    "        \n",
    "        if likelihoods:  # If we have valid results\n",
    "            # Find minimum likelihood\n",
    "            min_bayes_ll = min(likelihoods)\n",
    "            best_idx = likelihoods.index(min_bayes_ll)\n",
    "            \n",
    "            # Save best fitting parameters\n",
    "            best_params = results[best_idx]\n",
    "            beta = best_params[0]\n",
    "            bias = best_params[1]\n",
    "            gamma_pos = best_params[2]\n",
    "            gamma_neg = best_params[3]\n",
    "            \n",
    "            # Store results\n",
    "            params['subjNum'].append(sub_num)\n",
    "            params['subjBetaParam'].append(beta)\n",
    "            params['subjBias'].append(bias)\n",
    "            params['subjGammaPos'].append(gamma_pos)\n",
    "            params['subjGammaNeg'].append(gamma_neg)\n",
    "            params['subjBayesLL'].append(min_bayes_ll)\n",
    "            \n",
    "            # Save intermediate results\n",
    "            with open('m1_PD_BRL.pkl', 'wb') as f:\n",
    "                pickle.dump(params, f)\n",
    "\n",
    "# Compute AIC\n",
    "num_params = len(bounds)\n",
    "params['subjAIC'] = [-2 * ll - 2 * num_params for ll in params['subjBayesLL']]\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'sub_num': params['subjNum'],\n",
    "    'betaParam': params['subjBetaParam'],\n",
    "    'bias': params['subjBias'],\n",
    "    'gammaPos': params['subjGammaPos'],\n",
    "    'gammaNeg': params['subjGammaNeg'],\n",
    "    'BayesLL': params['subjBayesLL'],\n",
    "    'AIC': params['subjAIC']\n",
    "})\n",
    "\n",
    "# Save to Excel file\n",
    "results_df.to_csv('PD_BRL_fitting_results.csv', index=False)\n",
    "\n",
    "print(\"Model fitting completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47353fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
